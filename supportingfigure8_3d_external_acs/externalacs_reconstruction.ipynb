{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import importlib \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import scipy as sp\n",
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from bart import bart\n",
    "from utils import cfl\n",
    "from utils import signalprocessing as sig\n",
    "from utils import models\n",
    "from utils import iterative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining helper functions and the SPARK model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft3(x):\n",
    "    return sig.fft(sig.fft(sig.fft(x,-3),-2),-1)\n",
    "\n",
    "def ifft3(x):\n",
    "    return sig.ifft(sig.ifft(sig.ifft(x,-3),-2),-1)\n",
    "\n",
    "class SPARK_3D_net(nn.Module):\n",
    "    def __init__(self,coils,kernelsize,acsx,acsy,acsz):\n",
    "        super().__init__()\n",
    "        self.acsx = acsx\n",
    "        self.acsy = acsy\n",
    "        self.acsz = acsz\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(coils*2,coils*2,kernelsize,padding=1,bias = False)\n",
    "        self.conv2 = nn.Conv3d(coils*2,coils,1,padding=0,bias=False)\n",
    "        self.conv3 = nn.Conv3d(coils, coils*2, kernelsize, padding=1, bias=False)\n",
    "        self.conv4 = nn.Conv3d(coils*2,coils*2,kernelsize,padding=1,bias = False)\n",
    "        self.conv5 = nn.Conv3d(coils*2,coils,1,padding=0,bias=False)\n",
    "        self.conv6 = nn.Conv3d(coils, coils*2, kernelsize, padding=1, bias=False)\n",
    "        self.conv7 = nn.Conv3d(coils*2, coils, kernelsize, padding=1, bias=False)\n",
    "        self.conv8 = nn.Conv3d(coils, coils//4, 1, padding=0, bias=False)\n",
    "        self.conv9 = nn.Conv3d(coils//4, 1, kernelsize, padding=1, bias=False)  \n",
    "        \n",
    "    def naliniRelu(self,inp):\n",
    "        #An attempt at implementing Nalini's custom nonlinearity, from \"Joint Frequency- and Image-Space Learning for Fourier Imaging\"\n",
    "        return inp + F.relu((inp-1)/2) + F.relu((-inp-1)/2)        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.naliniRelu(self.conv1(x))\n",
    "        y = self.naliniRelu(self.conv2(y))\n",
    "        y = self.naliniRelu(self.conv3(y))\n",
    "        y = x + y\n",
    "        z = self.naliniRelu(self.conv4(y))\n",
    "        z = self.naliniRelu(self.conv5(z))\n",
    "        z = self.naliniRelu(self.conv6(z))\n",
    "        out = z  + y\n",
    "        out = self.conv9(self.naliniRelu(self.conv8(self.naliniRelu(self.conv7(out)))))\n",
    "        \n",
    "        loss_out = out[:,:,self.acsx[0]:self.acsx[-1]+1,self.acsy[0]:self.acsy[-1]+1,self.acsz[0]:self.acsz[-1]+1]\n",
    "\n",
    "        return out, loss_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the parameters and loading the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the dataset... ',end='')\n",
    "\n",
    "start = time.time()\n",
    "#Loading fully sampled kspace, grappa recon, and parmaters for BRAIN dataset\n",
    "kspace       = np.transpose(cfl.readcfl('data/kspaceFullFor3dsparkAcsrec'),(3,0,1,2))\n",
    "kspaceGrappa = np.transpose(cfl.readcfl('data/kspaceGrappaFor3dsparkAcsrec'),(3,0,1,2))\n",
    "for3dspark   = sp.io.loadmat('data/for3DsparkAcsrec.mat')['for3Dspark'][0][0]\n",
    "\n",
    "[C,M,N,P] = kspace.shape\n",
    "\n",
    "Rx = for3dspark[0][0][0]\n",
    "Ry = for3dspark[0][0][1]\n",
    "Rz = for3dspark[0][0][2]\n",
    "\n",
    "acsx = for3dspark[1][0][0]\n",
    "acsy = for3dspark[1][0][2]\n",
    "acsz = for3dspark[1][0][2]\n",
    "\n",
    "mask = for3dspark[3]\n",
    "\n",
    "#Defining some SPARK parameters\n",
    "normalizationflag = 1\n",
    "measuredReplace   = 1  #If we want to replace measured data (as well as ACS)\n",
    "iterations        = 1000 \n",
    "learningRate      = .002\n",
    "kernelsize        = 3\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Elapsed Time is %.3f seconds' % (time.time()-start))\n",
    "\n",
    "print('GRAPPA Parameters: ')\n",
    "print('  Dimensions:   %d x %d x %d x %d' %(C,M,N,P))\n",
    "print('  Acceleration: %d x %d x %d' % (Rx,Ry,Rz))\n",
    "print('  ACS Sizes:    %d x %d x %d' % (acsx,acsy,acsz))\n",
    "\n",
    "print('SPARK Parameters: ')\n",
    "print('  Iterations: %d' % iterations)\n",
    "print('  Stepsize:   %.3f' % learningRate)\n",
    "print('  Kernel:     %d' % kernelsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating zero filled acs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Generating zerofilled kspace\n",
    "acsregionX = np.arange(M//2 - acsx // 2,M//2 + acsx//2) \n",
    "acsregionY = np.arange(N//2 - acsy // 2,N//2 + acsy//2) \n",
    "acsregionZ = np.arange(P//2 - acsz // 2,P//2 + acsz//2) \n",
    "\n",
    "kspaceAcsZerofilled = np.zeros(kspace.shape,dtype = complex)\n",
    "kspaceAcsZerofilled[:,acsregionX[0]:acsregionX[acsx-1]+1,acsregionY[0]:acsregionY[acsy-1]+1,acsregionZ[0]:acsregionZ[acsz-1]+1] = \\\n",
    "    kspace[:,acsregionX[0]:acsregionX[acsx-1]+1,acsregionY[0]:acsregionY[acsy-1]+1,acsregionZ[0]:acsregionZ[acsz-1]+1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating ACS replaced GRAPPA reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Generating ACS replaced GRAPPA recon\n",
    "tmp = np.copy(kspaceGrappa)\n",
    "tmp[:,acsregionX[0]:acsregionX[acsx-1]+1,acsregionY[0]:acsregionY[acsy-1]+1,acsregionZ[0]:acsregionZ[acsz-1]+1] = \\\n",
    "    kspace[:,acsregionX[0]:acsregionX[acsx-1]+1,acsregionY[0]:acsregionY[acsy-1]+1,acsregionZ[0]:acsregionZ[acsz-1]+1]\n",
    "grappa = sig.rsos(ifft3(tmp),-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Reformatting kspace for SPARK\n",
    "kspaceAcsCrop   = kspace[:,acsregionX[0]:acsregionX[acsx-1]+1,acsregionY[0]:acsregionY[acsy-1]+1,acsregionZ[0]:acsregionZ[acsz-1]+1] \n",
    "kspaceAcsGrappa = kspaceGrappa[:,acsregionX[0]:acsregionX[acsx-1]+1,acsregionY[0]:acsregionY[acsy-1]+1,acsregionZ[0]:acsregionZ[acsz-1]+1] \n",
    "kspaceAcsDifference = kspaceAcsCrop - kspaceAcsGrappa\n",
    "\n",
    "acs_difference_real = np.real(kspaceAcsDifference)\n",
    "acs_difference_imag = np.imag(kspaceAcsDifference)\n",
    "\n",
    "kspace_grappa = np.copy(kspaceGrappa)\n",
    "kspace_grappa_real  = np.real(kspace_grappa)\n",
    "kspace_grappa_imag  = np.imag(kspace_grappa)\n",
    "kspace_grappa_split = np.concatenate((kspace_grappa_real, kspace_grappa_imag), axis=0)\n",
    "\n",
    "#Let's do some normalization\n",
    "chan_scale_factors_real = np.zeros(C,dtype = 'float')\n",
    "chan_scale_factors_imag = np.zeros(C,dtype = 'float')\n",
    "\n",
    "if(normalizationflag):\n",
    "    scale_factor_input  = 1/np.amax(np.abs(kspace_grappa_split))\n",
    "    kspace_grappa_split *= scale_factor_input\n",
    "\n",
    "for c in range(C):\n",
    "    if(normalizationflag):\n",
    "        scale_factor_real = 1/np.amax(np.abs(acs_difference_real[c,:,:,:]))\n",
    "        scale_factor_imag = 1/np.amax(np.abs(acs_difference_imag[c,:,:,:]))\n",
    "    else:\n",
    "        scale_factor_real = 1\n",
    "        scale_factor_imag = 1\n",
    "\n",
    "    chan_scale_factors_real[c] = scale_factor_real\n",
    "    chan_scale_factors_imag[c] = scale_factor_imag\n",
    "\n",
    "    acs_difference_real[c,:,:,:] *= scale_factor_real\n",
    "    acs_difference_imag[c,:,:,:] *= scale_factor_imag\n",
    "\n",
    "acs_difference_real = np.expand_dims(np.expand_dims(acs_difference_real,axis=1), axis=1)\n",
    "acs_difference_imag = np.expand_dims(np.expand_dims(acs_difference_imag,axis=1), axis=1)\n",
    "\n",
    "kspace_grappa_split = torch.unsqueeze(torch.from_numpy(kspace_grappa_split),axis = 0)\n",
    "kspace_grappa_split = kspace_grappa_split.to(device, dtype=torch.float)\n",
    "\n",
    "acs_difference_real = torch.from_numpy(acs_difference_real)\n",
    "acs_difference_real = acs_difference_real.to(device, dtype=torch.float)\n",
    "\n",
    "acs_difference_imag = torch.from_numpy(acs_difference_imag)\n",
    "acs_difference_imag = acs_difference_imag.to(device, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the SPARK network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the real spark network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_models      = {}\n",
    "real_model_names = []\n",
    "\n",
    "criterion   = nn.MSELoss()\n",
    "\n",
    "realLoss = np.zeros((iterations,C)) #Record the loss over epoch of each model to analyze later\n",
    "\n",
    "for c in range(0,C):\n",
    "    model_name = 'model'+ 'C' + str(c) + 'r'\n",
    "    model = SPARK_3D_net(coils=C,kernelsize=kernelsize,acsx=acsregionX,acsy=acsregionY,acsz=acsregionZ)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    print('Training {}'.format(model_name))\n",
    "    start = time.time()\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(),lr=learningRate)\n",
    "    running_loss = 0\n",
    "\n",
    "    for epoch in range(iterations):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        _,loss_out = model(kspace_grappa_split)\n",
    "        loss = criterion(loss_out,acs_difference_real[c,:,:,:,:,:]) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss = loss.item()\n",
    "        realLoss[epoch,c] = running_loss;\n",
    "        \n",
    "        if(epoch == 0):\n",
    "            print('   Starting Loss: %.10f' % running_loss)\n",
    "\n",
    "    real_model_names.append(model_name)\n",
    "    real_models.update({model_name:model})\n",
    "    \n",
    "    print('   Ending Loss:   %.10f' % (running_loss))\n",
    "    print('   Training Time: %.3f seconds' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the imaginary SPARK network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imag_models      = {}\n",
    "imag_model_names = []\n",
    "\n",
    "criterion   = nn.MSELoss()\n",
    "\n",
    "imagLoss = np.zeros((iterations,C)) #Record the loss over epoch of each model to analyze later\n",
    "\n",
    "for c in range(0,C):\n",
    "    model_name = 'model'+ 'C' + str(c) + 'i'\n",
    "    model = SPARK_3D_net(coils=C,kernelsize=kernelsize,acsx=acsregionX,acsy=acsregionY,acsz=acsregionZ)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    print('Training {}'.format(model_name))\n",
    "    start = time.time()\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(),lr=learningRate)\n",
    "    running_loss = 0\n",
    "\n",
    "    for epoch in range(iterations):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        _,loss_out = model(kspace_grappa_split)\n",
    "        loss = criterion(loss_out,acs_difference_imag[c,:,:,:,:,:]) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss = loss.item()\n",
    "        imagLoss[epoch,c] = running_loss;\n",
    "        \n",
    "        if(epoch == 0):\n",
    "            print('   Starting Loss: %.10f' % running_loss)\n",
    "            \n",
    "    imag_model_names.append(model_name)\n",
    "    imag_models.update({model_name:model})\n",
    "    \n",
    "    print('   Ending Loss:   %.10f' % (running_loss))\n",
    "    print('   Training Time: %.3f seconds' % (time.time() - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing SPARK correction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Performing coil-by-coil correction... ', end = '')\n",
    "start = time.time()\n",
    "\n",
    "kspaceCorrected = np.zeros((C,M,N,P),dtype = complex)\n",
    "\n",
    "for c in range(0,C):\n",
    "    #Perform reconstruction coil by coil\n",
    "    model_namer = 'model' + 'C' + str(c) + 'r'\n",
    "    model_namei = 'model' + 'C' + str(c) + 'i'\n",
    "\n",
    "    real_model = real_models[model_namer]\n",
    "    imag_model = imag_models[model_namei]\n",
    "\n",
    "    correctionr = real_model(kspace_grappa_split)[0].cpu().detach().numpy()\n",
    "    correctioni = imag_model(kspace_grappa_split)[0].cpu().detach().numpy() \n",
    "    \n",
    "    kspaceCorrected[c,:,:,:] = correctionr[0,0,:,:,:]/chan_scale_factors_real[c] + \\\n",
    "        1j * correctioni[0,0,:,:,:] / chan_scale_factors_imag[c] + kspaceGrappa[c,:,:,:]\n",
    "    \n",
    "print('Elapsed Time is %.3f seconds' % (time.time()-start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing ACS replacement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#Perofrming ACS replacement and ifft/rsos coil combine reconstruction\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "print('Performing ACS replacement, ifft, and rsos coil combination... ', end = '')\n",
    "start = time.time()\n",
    "\n",
    "#ACS replaced\n",
    "kspaceCorrectedReplaced    = np.copy(kspaceCorrected)\n",
    "\n",
    "kspaceCorrectedReplaced[:,acsregionX[0]:acsregionX[acsx-1]+1,acsregionY[0]:acsregionY[acsy-1]+1,acsregionZ[0]:acsregionZ[acsz-1]+1] = \\\n",
    "    kspace[:,acsregionX[0]:acsregionX[acsx-1]+1,acsregionY[0]:acsregionY[acsy-1]+1,acsregionZ[0]:acsregionZ[acsz-1]+1]\n",
    "\n",
    "#Sampled Data replacement\n",
    "if(measuredReplace):\n",
    "    kspaceCorrectedReplaced[:,::Rx,::Ry,::Rz] = kspace[:,::Rx,::Ry,::Rz]\n",
    "    kspaceCorrectedReplaced *= np.expand_dims(mask,axis=0)\n",
    "    \n",
    "#Perform IFFT and coil combine\n",
    "truth  = for3dspark[2]\n",
    "grappa = sig.rsos(ifft3(tmp),-4)\n",
    "spark  = sig.rsos(ifft3(kspaceCorrectedReplaced),-4)\n",
    "print('Elapsed Time is %.3f seconds' % (time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print('Saving results... ', end = '')\n",
    "start = time.time()\n",
    "results = {'groundTruth': np.squeeze(truth),\n",
    "           'grappa': np.squeeze(grappa),\n",
    "           'spark': np.squeeze(spark),\n",
    "           'Ry': Ry,\n",
    "           'Rz': Rz,\n",
    "           'acsy': acsy,\n",
    "           'acsz': acsz,           \n",
    "           'Iterations': iterations,\n",
    "           'learningRate': learningRate,\n",
    "           'realLoss':realLoss,\n",
    "           'imagLoss':imagLoss}\n",
    "\n",
    "sp.io.savemat('3dVolumeSparkAcsrecon', results, oned_as='row')\n",
    "print('Elapsed Time is %.3f seconds' % (time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
