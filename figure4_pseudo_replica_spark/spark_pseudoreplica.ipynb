{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Trying to replicate pseudo-replica technique as closely as possible when performing retained \"SNR\" analysis with SPRAK. Will try to follow this procedure for now:\n",
    "-Train SPARK model just using base-line reconstruction\n",
    "-Correct all noise-instances + baseline with one trained SPARK model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import cfl\n",
    "from utils import signalprocessing as sig\n",
    "from utils import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forspark   = sp.io.loadmat('forspark/forspark_Rx6Ry1.mat')['forspark']\n",
    "\n",
    "kspace_orig    = np.transpose(cfl.readcfl('forspark/kspace_orig_Rx6Ry1'),axes = (2,0,1))\n",
    "kspace_grappa  = np.transpose(cfl.readcfl('forspark/kspace_grappa_noisy_Rx6Ry1'),axes = (3,2,0,1))\n",
    "\n",
    "Rx    = forspark[0][0][0][0][0]\n",
    "Ry    = forspark[0][0][1][0][0]\n",
    "acsx  = forspark[0][0][2][0][0]\n",
    "acsy  = forspark[0][0][3][0][0]\n",
    "\n",
    "baseline_coils = np.expand_dims(np.transpose(forspark[0][0][4],(2,0,1)),axis = 0)\n",
    "coils          = np.expand_dims(np.transpose(forspark[0][0][5],(2,0,1)),axis = 0)\n",
    "\n",
    "kspace       = np.expand_dims(kspace_orig,axis = 0)\n",
    "kspaceGrappa = sig.fft2c(baseline_coils);\n",
    "\n",
    "[E,C,M,N] = kspace.shape\n",
    "\n",
    "#-Spark parameters\n",
    "iterations        = 200\n",
    "learningRate      = .0075\n",
    "normalizationflag = 1\n",
    "normalizeAll      = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate ACS for training network from just base-line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate zero-filled ACS\n",
    "acsregionX = np.arange(M//2 - acsx // 2,M//2 + acsx//2) \n",
    "acsregionY = np.arange(N//2 - acsy // 2,N//2 + acsy//2) \n",
    "\n",
    "kspaceAcsZerofilled = np.zeros((E,C,M,N),dtype = complex)\n",
    "kspaceAcsZerofilled[:,:,acsregionX[0]:acsregionX[acsx-1]+1,acsregionY[0]:acsregionY[acsy-1]+1] = kspace[:,:,acsregionX[0]:acsregionX[acsx-1]+1,acsregionY[0]:acsregionY[acsy-1]+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARK helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformattingKspaceForSpark(inputKspace,kspaceOriginal,acsregionX,acsregionY,acsx,acsy,normalizationflag):\n",
    "    [E,C,_,_] = inputKspace.shape\n",
    "    kspaceAcsCrop     = kspaceOriginal[:,:,acsregionX[0]:acsregionX[acsx-1]+1,acsregionY[0]:acsregionY[acsy-1]+1] \n",
    "    #Ground truth measured ACS data, will be used as the ground truth to compute kspace error we want learn\n",
    "    kspaceAcsGrappa   = inputKspace[:,:,acsregionX[0]:acsregionX[acsx-1]+1,acsregionY[0]:acsregionY[acsy-1]+1] \n",
    "    #GRAPPA reconstructed ACS region.  kspaceAcsCrop - kspaceAcsGrappa = d will be the supervised error we try to learn\n",
    "    kspaceAcsDifference = kspaceAcsCrop - kspaceAcsGrappa\n",
    "\n",
    "    #Splitting the difference into the real and imaginary part for the network\n",
    "    acs_difference_real = np.real(kspaceAcsDifference)\n",
    "    acs_difference_imag = np.imag(kspaceAcsDifference)\n",
    "\n",
    "    #print('acs_difference_real shape: ' + str(acs_difference_real.shape))\n",
    "    #print('acs_difference_imag shape: ' + str(acs_difference_imag.shape))\n",
    "\n",
    "    #Adding the batch dimension\n",
    "    kspace_grappa = np.copy(inputKspace)\n",
    "    kspace_grappa_real  = np.real(kspace_grappa)\n",
    "    kspace_grappa_imag  = np.imag(kspace_grappa)\n",
    "    kspace_grappa_split = np.concatenate((kspace_grappa_real, kspace_grappa_imag), axis=1)\n",
    "\n",
    "    #print('kspace_grappa_split shape: ' + str(kspace_grappa_split.shape))\n",
    "\n",
    "    #Let's do some normalization\n",
    "    chan_scale_factors_real = np.zeros((E,C),dtype = 'float')\n",
    "    chan_scale_factors_imag = np.zeros((E,C),dtype = 'float')\n",
    "\n",
    "    for e in range(E):\n",
    "        if(normalizationflag):\n",
    "            scale_factor_input = 1/np.amax(np.abs(kspace_grappa_split[e,:,:,:]))\n",
    "            kspace_grappa_split[e,:,:,:] *= scale_factor_input\n",
    "\n",
    "        for c in range(C):\n",
    "            if(normalizationflag):\n",
    "                scale_factor_real = 1/np.amax(np.abs(acs_difference_real[e,c,:,:]))\n",
    "                scale_factor_imag = 1/np.amax(np.abs(acs_difference_imag[e,c,:,:]))\n",
    "            else:\n",
    "                scale_factor_real = 1\n",
    "                scale_factor_imag = 1\n",
    "\n",
    "            chan_scale_factors_real[e,c] = scale_factor_real\n",
    "            chan_scale_factors_imag[e,c] = scale_factor_imag\n",
    "\n",
    "            acs_difference_real[e,c,:,:] *= scale_factor_real\n",
    "            acs_difference_imag[e,c,:,:] *= scale_factor_imag\n",
    "\n",
    "    acs_difference_real = np.expand_dims(acs_difference_real, axis=2)\n",
    "    acs_difference_real = np.expand_dims(acs_difference_real, axis=2)\n",
    "    acs_difference_imag = np.expand_dims(acs_difference_imag, axis=2)\n",
    "    acs_difference_imag = np.expand_dims(acs_difference_imag, axis=2)\n",
    "\n",
    "    #print('acs_difference_real shape: ' + str(acs_difference_real.shape))\n",
    "    #print('acs_difference_imag shape: ' + str(acs_difference_imag.shape))\n",
    "\n",
    "    kspace_grappa_split = torch.from_numpy(kspace_grappa_split)\n",
    "    kspace_grappa_split = kspace_grappa_split.to(device, dtype=torch.float)\n",
    "    print('kspace_grappa_split shape: ' + str(kspace_grappa_split.shape))\n",
    "\n",
    "    acs_difference_real = torch.from_numpy(acs_difference_real)\n",
    "    acs_difference_real = acs_difference_real.to(device, dtype=torch.float)\n",
    "    print('acs_difference_real shape: ' + str(acs_difference_real.shape))\n",
    "\n",
    "    acs_difference_imag = torch.from_numpy(acs_difference_imag)\n",
    "    acs_difference_imag = acs_difference_imag.to(device, dtype=torch.float)\n",
    "    print('acs_target_imag shape: ' + str(acs_difference_imag.shape))\n",
    "    \n",
    "    return kspace_grappa_split, acs_difference_real, acs_difference_imag, chan_scale_factors_real, chan_scale_factors_imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingSparkNetwork(kspaceGrappaSplit,acsDifferenceReal,acsDifferenceImag,acsx,acsy,learningRate,iterations):\n",
    "    '''\n",
    "    Trains a SPARK networks given some appropriately formatted grappa kspace, acsDifferenceReal, and acsDifferenceImaginary\n",
    "    Inputs:\n",
    "        kspaceGrappaSplit: allContrasts x 2 * allChannels x M x N,             Grappa reconstructed kspace which will \n",
    "                                                                               be used to learn error\n",
    "        acsDifferenceReal: allContrasts x allChaannels x 1 x 1 x M x N,        Difference between measured and GRAPPA\n",
    "                                                                               ACS real portion\n",
    "        acsDifferenceImag: allContrasts x allChaannels x 1 x 1 M x N,          Difference between measured and GRAPPA\n",
    "                                                                               ACS imag portion             \n",
    "        acs:               acss x 1,                                           Indices of ACS region\n",
    "        learningRate:      scalar,                                             Learaning rate for the networks\n",
    "        iterations:        scalar,                                             Number of iterations we want to train\n",
    "    Outputs:\n",
    "        A network which should reconstruct each contrast and channel        \n",
    "    '''\n",
    "    \n",
    "    [E,C,_,_,_,_] = acsDifferenceReal.shape\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    #Training the real models\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    real_models      = {}\n",
    "    real_model_names = []\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for e in range(0,E):\n",
    "        for c in range(0,C):\n",
    "            model_name = 'model' + 'E' + str(e) + 'C' + str(c) + 'r'\n",
    "            model = models.SPARK_Netv2(coils = C,kernelsize = 3,acsx = acsx, acsy = acsy)\n",
    "            \n",
    "            model.to(device)\n",
    "            \n",
    "            kspsplit = torch.unsqueeze(kspaceGrappaSplit[e,:,:,:],axis = 0)\n",
    "            \n",
    "            print('Training {}'.format(model_name))\n",
    "            \n",
    "            optimizer = optim.Adam(model.parameters(),lr=learningRate)\n",
    "            running_loss = 0\n",
    "            \n",
    "            for epoch in range(iterations):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                _,loss_out = model(kspsplit)\n",
    "                loss = criterion(loss_out,acsDifferenceReal[e,c,:,:,:,:])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss = loss.item()\n",
    "                if(epoch == 0):\n",
    "                    print('Training started , loss = %.10f' % (running_loss))\n",
    "            \n",
    "            real_model_names.append(model_name)\n",
    "            real_models.update({model_name:model})\n",
    "            \n",
    "            print('Training Complete, loss = %.10f' % (running_loss))\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    #Training the imaginary model\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    imag_models      = {}\n",
    "    imag_model_names = []\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for e in range(0,E):\n",
    "        for c in range(0,C):\n",
    "            model_name = 'model' + 'E' + str(e) + 'C' + str(c) + 'i'            \n",
    "            model = models.SPARK_Netv2(coils = C,kernelsize = 3,acsx = acsx, acsy = acsy)\n",
    "            \n",
    "            model.to(device)\n",
    "            \n",
    "            kspsplit = torch.unsqueeze(kspaceGrappaSplit[e,:,:,:],axis = 0)\n",
    "            \n",
    "            print('Training {}'.format(model_name))\n",
    "            \n",
    "            optimizer    = optim.Adam(model.parameters(),lr = learningRate)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for epoch in range(iterations):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                _,loss_out = model(kspsplit)\n",
    "                loss = criterion(loss_out,acsDifferenceImag[e,c,:,:,:,:])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss = loss.item()\n",
    "                if(epoch == 0):\n",
    "                    print('Training started , loss = %.10f' % (running_loss))\n",
    "                \n",
    "            imag_model_names.append(model_name)\n",
    "            imag_models.update({model_name : model})\n",
    "\n",
    "            print('Training Complete, loss = %.10f' % (running_loss))\n",
    "\n",
    "    return real_models,real_model_names,imag_models,imag_model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applySparkCorrection(kspaceToCorrect,kspaceGrappaSplit,real_model,imag_model,chanScaleFactorReal,chanScaleFactorImag):\n",
    "    '''\n",
    "    Given a set of models trained for a particular contrast, apply SPARK to all of the contrasts\n",
    "    Inputs:\n",
    "        kspaceToCorrect   - M x N,       Kspace that we want to correct\n",
    "        kspaceGrappasplit - allcoils x M x N  Kspace that will be used to reconstuct the particular for this kspace\n",
    "        real_model      - model          Model for correcting the real component\n",
    "        imag_model      - model          Model for correcting the imaginary component\n",
    "        chanScaleFactor - Scalar         Scaling parameter for the particular piece of kspace which is corrected\n",
    "    outputs:\n",
    "        kspaceCorrected - M x N       Corrected kspace\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    correctionr = real_model(torch.unsqueeze(kspaceGrappaSplit,axis=0))[0].cpu().detach().numpy()\n",
    "    correctioni = imag_model(torch.unsqueeze(kspaceGrappaSplit,axis=0))[0].cpu().detach().numpy()\n",
    "    corrected = correctionr[0,0,:,:]/chanScaleFactorReal + 1j * correctioni[0,0,:,:] / chanScaleFactorImag + kspaceToCorrect\n",
    "    \n",
    "    return corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training network on just baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Reformatting the data\n",
    "[kspace_grappa_split, acs_difference_real, acs_difference_imag,chan_scale_factors_real,chan_scale_factors_imag] = \\\n",
    "    reformattingKspaceForSpark(kspaceGrappa,kspaceAcsZerofilled,acsregionX,acsregionY,acsx,acsy,normalizationflag)\n",
    "\n",
    "realSparkGrappaModels,realSparkGrappaNames,imagSparkGrappaModels,imagSparkGrappaNames = \\\n",
    "    trainingSparkNetwork(kspace_grappa_split,acs_difference_real,acs_difference_imag,acsregionX,acsregionY,learningRate,iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correcting just the baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will use each model contrast to reconstruct each recon contrast\n",
    "kspaceCorrected    = np.zeros((E,C,M,N),dtype = complex)\n",
    "\n",
    "\n",
    "for reconContrast in range(0,E):\n",
    "    for c in range(0,C):\n",
    "        #Perform reconstruction coil by coil\n",
    "        model_namer = 'model' + 'E' + str(reconContrast) + 'C' + str(c) + 'r'\n",
    "        model_namei = 'model' + 'E' + str(reconContrast) + 'C' + str(c) + 'i'\n",
    "\n",
    "        real_model = realSparkGrappaModels[model_namer]\n",
    "        imag_model = imagSparkGrappaModels[model_namei]\n",
    "\n",
    "        kspaceToCorrect   = kspaceGrappa[reconContrast,c,:,:]\n",
    "        kspaceGrappaSplit = kspace_grappa_split[reconContrast,:,:,:]\n",
    "\n",
    "        currentCorrected = \\\n",
    "                applySparkCorrection(kspaceToCorrect,kspaceGrappaSplit,real_model,imag_model,\\\n",
    "                    chan_scale_factors_real[reconContrast,c], chan_scale_factors_imag[reconContrast,c])\n",
    "\n",
    "        kspaceCorrected[reconContrast,c,:,:] = currentCorrected  \n",
    "        \n",
    "kspace_baseline_spark = np.copy(kspaceCorrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coil-combining grappa_baseline, spark_baseline, and truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kspaceCorrected    = np.zeros((E,C,M,N),dtype = complex)\n",
    "\n",
    "for reconContrast in range(0,E):\n",
    "    for c in range(0,C):\n",
    "        #Perform reconstruction coil by coil\n",
    "        model_namer = 'model' + 'E' + str(reconContrast) + 'C' + str(c) + 'r'\n",
    "        model_namei = 'model' + 'E' + str(reconContrast) + 'C' + str(c) + 'i'\n",
    "\n",
    "        real_model = realSparkGrappaModels[model_namer]\n",
    "        imag_model = imagSparkGrappaModels[model_namei]\n",
    "\n",
    "        kspaceToCorrect   = kspaceGrappa[reconContrast,c,:,:]\n",
    "        kspaceGrappaSplit = kspace_grappa_split[reconContrast,:,:,:]\n",
    "\n",
    "        currentCorrected = \\\n",
    "                applySparkCorrection(kspaceToCorrect,kspaceGrappaSplit,real_model,imag_model,\\\n",
    "                    chan_scale_factors_real[reconContrast,c], chan_scale_factors_imag[reconContrast,c])\n",
    "\n",
    "        kspaceCorrected[reconContrast,c,:,:] = currentCorrected   \n",
    "kspaces_spark = np.copy(kspaceCorrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare just baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = lambda x: np.sum(np.conj(coils) * x, axis = -3)/(1e-12 +np.sum(coils * np.conj(coils),-3))\n",
    "\n",
    "truth             = cc(sig.ifft2c(kspace))\n",
    "baseline_grappa   = cc(baseline_coils)\n",
    "baseline_spark    = cc(sig.ifft2c(kspace_baseline_spark))\n",
    "\n",
    "print(\"BASELINE RMSES\")\n",
    "print(\"  grappa: %.2f\" % (sig.rmse(truth,baseline_grappa)*100))\n",
    "print(\"  spark:  %.2f\" % (sig.rmse(truth,baseline_spark)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = np.concatenate((truth,baseline_grappa,baseline_spark),axis = 0)\n",
    "sig.mosaic(sig.nor(display),1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply SPARK correction to all other grappa reconstructed k-spaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kspaceGrappa = np.copy(kspace_grappa)\n",
    "[E,C,M,N] = kspaceGrappa.shape\n",
    "#Reformatting the data\n",
    "[kspace_grappa_split, acs_difference_real, acs_difference_imag,chan_scale_factors_real,chan_scale_factors_imag] = \\\n",
    "    reformattingKspaceForSpark(kspaceGrappa,kspaceAcsZerofilled,acsregionX,acsregionY,acsx,acsy,normalizationflag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kspaceCorrectedReplica    = np.zeros((E,C,M,N),dtype = complex)\n",
    "\n",
    "for reconContrast in range(0,E):\n",
    "    for c in range(0,C):\n",
    "        #Perform reconstruction coil by coil\n",
    "        model_namer = 'model' + 'E' + str(0) + 'C' + str(c) + 'r'\n",
    "        model_namei = 'model' + 'E' + str(0) + 'C' + str(c) + 'i'\n",
    "\n",
    "        real_model = realSparkGrappaModels[model_namer]\n",
    "        imag_model = imagSparkGrappaModels[model_namei]\n",
    "\n",
    "        kspaceToCorrect   = kspaceGrappa[reconContrast,c,:,:]\n",
    "        kspaceGrappaSplit = kspace_grappa_split[reconContrast,:,:,:]\n",
    "\n",
    "        currentCorrected = \\\n",
    "                applySparkCorrection(kspaceToCorrect,kspaceGrappaSplit,real_model,imag_model,\\\n",
    "                    chan_scale_factors_real[0,c], chan_scale_factors_imag[0,c])\n",
    "\n",
    "        kspaceCorrectedReplica[reconContrast,c,:,:] = currentCorrected   \n",
    "kspaces_spark_montecarlo = np.copy(kspaceCorrectedReplica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute spark and GRAPPA monte-carlo replicas and compute RMSE's acrooss all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grappa_montecarlo = cc(sig.ifft2c(kspace_grappa))\n",
    "spark_montecarlo  = cc(sig.ifft2c(kspaces_spark_montecarlo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsespark  = np.zeros((E,1))\n",
    "rmsegrappa = np.zeros((E,1))\n",
    "\n",
    "for ee in range(0,E):\n",
    "    rmsespark[ee]  = sig.rmse(truth,grappa_montecarlo[ee,:,:])\n",
    "    rmsegrappa[ee] = sig.rmse(truth,spark_montecarlo[ee,:,:])\n",
    "\n",
    "plt.plot(rmsespark)\n",
    "plt.plot(rmsegrappa)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display a random example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randint = np.random.randint(0,E)\n",
    "display = np.concatenate((grappa_montecarlo[randint:randint+1,:,:],spark_montecarlo[randint:randint+1,:,:]),axis =0)\n",
    "sig.mosaic(sig.nor(display),1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'baseline_grappa':   np.squeeze(baseline_grappa),\n",
    "           'baseline_spark' :   np.squeeze(baseline_spark),\n",
    "           'grappa_montecarlo': np.squeeze(grappa_montecarlo),\n",
    "           'spark_montecarlo' : np.squeeze(spark_montecarlo),\n",
    "           'Rx': Rx,\n",
    "           'Ry': Ry,\n",
    "           'acsx': acsx,\n",
    "           'acsy': acsy,           \n",
    "           'Iterations': iterations,\n",
    "           'learningRate': learningRate}\n",
    "\n",
    "sp.io.savemat('results/results_Rx%dRy%d.mat' % (Rx,Ry), results, oned_as='row')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
