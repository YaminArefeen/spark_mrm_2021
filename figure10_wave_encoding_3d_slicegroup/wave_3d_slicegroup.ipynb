{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import scipy as sp\n",
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from bart import bart\n",
    "from utils import cfl\n",
    "from utils import signalprocessing as sig\n",
    "from utils import models\n",
    "from utils import iterative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading dataset and selecting slices/psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Load Fx^H * Fy^H * Fz^H * wave_data\n",
    "img_yz = np.transpose(cfl.readcfl('data/img_yz'),(3,2,0,1))\n",
    "\n",
    "#-Load y/z wave psf's\n",
    "PsfY_fit = np.expand_dims(np.expand_dims(cfl.readcfl('data/PsfY_fit'),0),0)\n",
    "PsfZ_fit = np.expand_dims(np.expand_dims(cfl.readcfl('data/PsfZ_fit'),0),0)\n",
    "PsfZ_fit = np.transpose(PsfZ_fit,(0,3,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[C,P,Nro,N] = img_yz.shape\n",
    "\n",
    "#-Some parameters on the sms acquisition \n",
    "beginningSliceIndex = 10\n",
    "numslices_all       = 4\n",
    "slicedistance       = P // numslices_all\n",
    "fovshift            = 3 #FOV shift factor 'blipped caipi' esque stuff\n",
    "\n",
    "#-acquisition parameters \n",
    "Ry                  = 5\n",
    "os                  = 3   #How much wave encoding was oversampled by\n",
    "\n",
    "#-Iterative method parameters\n",
    "senseIterations = 20\n",
    "cudaflag        = 1\n",
    "\n",
    "learningRate      = .0075\n",
    "sparkIterations   = 200\n",
    "normalizationflag = 1\n",
    "\n",
    "slices_all = np.linspace(beginningSliceIndex,beginningSliceIndex + slicedistance * (numslices_all-1),numslices_all).astype(int)\n",
    "slices     = slices_all[1::] #Remove frist empty slice\n",
    "numslices  = numslices_all - 1\n",
    "\n",
    "#-Some SPARK parameters\n",
    "acsx = Nro \n",
    "acsy = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selecting slices and associated psf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_yz_slices = img_yz[:,slices,:,:]\n",
    "psf_slices    = PsfY_fit * PsfZ_fit[:,slices,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualizing slices to be aliased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_to_alias_coils = sig.ifft(np.conj(psf_slices) * sig.fft(img_yz_slices,-2),-2)\n",
    "slices_to_alias = sig.rsos(slices_to_alias_coils,-4)\n",
    "sig.mosaic(sig.nor(slices_to_alias),1,numslices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating cartesian k-space and coil profiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kspace_slices_cartesian = sig.fft2c(slices_to_alias_coils)\n",
    "\n",
    "coils_slices = np.zeros((C,numslices,Nro,N),dtype = complex)\n",
    "\n",
    "for ss in range(0,numslices):\n",
    "    print('Callibrating coils for slice %d/%d' % (ss + 1,numslices))\n",
    "    curksp  = np.expand_dims(np.transpose(kspace_slices_cartesian[:,ss,:,:],axes = (1,2,0)),2)\n",
    "    coils_slices[:,ss,:,:] = np.squeeze(np.transpose(bart(1,'ecalib -m 1 -c .5',curksp),(3,2,0,1)))\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applying fov shift to slices and sensitivities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Define the shift amounts\n",
    "if(fovshift > 0):\n",
    "    shifts = np.round(np.linspace(-(numslices / 2 - 1),numslices/2,numslices) * N / fovshift ).astype(int)\n",
    "else:\n",
    "    shifts = np.zeros((numslices)).astype(int)\n",
    "\n",
    "#-Define the function which performs the shifting\n",
    "def performshift(x,shift,direction = 1):\n",
    "    out = np.zeros(x.shape,dtype=complex)\n",
    "    \n",
    "    for ss in range(0,out.shape[-3]):\n",
    "        out[:,ss,:,:] = np.roll(x[:,ss,:,:],direction*shift[ss])\n",
    "    return out\n",
    "      \n",
    "#-Compute shifted slices in image space (as well as the shifted coils)\n",
    "slicesShiftedCoils  = performshift(slices_to_alias_coils,shifts)\n",
    "coils               = performshift(coils_slices,shifts)\n",
    "img_yz_slices_shift = performshift(img_yz_slices,shifts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualizing shifted slices and wave aliasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = np.squeeze(np.concatenate((np.expand_dims(sig.nor(sig.rsos(slicesShiftedCoils,-4)),0),\\\n",
    "                          np.expand_dims(sig.nor(sig.rsos(img_yz_slices_shift,-4)),0)),axis = 1))\n",
    "sig.mosaic(display,1,2*numslices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating cartesian k-space slice group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = lambda x: np.sum(x,axis = - 3, keepdims = True)\n",
    "exp = lambda x: np.repeat(x,repeats = numslices,axis = -3)\n",
    "acsregionX = np.arange((Nro*numslices)//2 - acsx // 2,(Nro*numslices)//2 + acsx//2) \n",
    "acsregionY = np.arange(N//2 - acsy // 2,N//2 + acsy//2) \n",
    "\n",
    "#-Generate the undersampling mask\n",
    "mask = np.zeros((C,1,Nro,N),dtype = complex)\n",
    "mask[:,:,:,::Ry] = 1\n",
    "\n",
    "maskAcs = np.zeros((C,1,Nro,N),dtype = complex)\n",
    "maskAcs[:,:,:,::Ry]       = 1\n",
    "maskAcs[:,:,:,acsregionY[0]:acsregionY[acsy-1]] = 1\n",
    "\n",
    "kspace    = col(mask * (sig.fft2c(slicesShiftedCoils)))\n",
    "kspaceAcs = col(maskAcs * (sig.fft2c(slicesShiftedCoils)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating slice group sense operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senseForward(x,maps,mask):\n",
    "    return mask * col(sig.fft2c(maps*x))\n",
    "def senseAdjoint(x,maps,mask):\n",
    "    xp = cp.get_array_module(x)\n",
    "    return xp.sum(xp.conj(maps)*(sig.ifft2c(exp(x))),-4,keepdims = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performing slice-group sense reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Compute the adjoint of the kspace data\n",
    "kadj = senseAdjoint(kspace,coils,mask)\n",
    "kadjAcs = senseAdjoint(kspaceAcs,coils,maskAcs)\n",
    "\n",
    "if(cudaflag):\n",
    "    coils   = cp.asarray(coils)\n",
    "    mask    = cp.asarray(mask)\n",
    "    maskAcs = cp.asarray(maskAcs)\n",
    "    kadj    = cp.asarray(kadj)\n",
    "    kadjAcs = cp.asarray(kadjAcs)\n",
    "    \n",
    "#-Defining the normal operator and performing the reconstruction\n",
    "normal = lambda x: senseAdjoint(senseForward(x.reshape(1,numslices,Nro,N),coils,mask),\\\n",
    "                                          coils,mask).ravel()\n",
    "\n",
    "normalAcs = lambda x: senseAdjoint(senseForward(x.reshape(1,numslices,Nro,N),coils,maskAcs),\\\n",
    "                                          coils,maskAcs).ravel()\n",
    "print('SENSE reconstruction ...',end='')\n",
    "smsSense = cp.asnumpy(iterative.conjgrad(normal,kadj.ravel(),kadj.ravel(),\\\n",
    "                                         ite = 20)).reshape(1,numslices,Nro,N)\n",
    "smsSenseAcs = cp.asnumpy(iterative.conjgrad(normalAcs,kadjAcs.ravel(),kadjAcs.ravel(),\\\n",
    "                                         ite = 20)).reshape(1,numslices,Nro,N)\n",
    "\n",
    "print(' Done.')\n",
    "\n",
    "coils = cp.asnumpy(coils)\n",
    "mask  = cp.asnumpy(mask)\n",
    "kadj  = cp.asnumpy(kadj)\n",
    "kadjAcs = cp.asnumpy(kadjAcs)\n",
    "maskAcs = cp.asnumpy(maskAcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluating slice-group sense reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viscrop = lambda x: x[:,768//2-128:768//2+128,:]\n",
    "    \n",
    "truth = viscrop(np.squeeze(performshift(np.expand_dims(np.sum(np.conj(coils) * slicesShiftedCoils,-4),axis = 0),shifts,-1),axis = 0))\n",
    "sense = viscrop(np.squeeze(performshift(np.expand_dims(np.reshape(smsSenseAcs,(numslices,Nro,N)),axis=0),shifts,-1),axis=0))\n",
    "\n",
    "display = sig.nor(np.concatenate((truth,sense),axis = 0))\n",
    "sig.mosaic(display,2,numslices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total rmse:   %.2f' % (sig.rmse(truth,sense)*100) )\n",
    "for ss in range(0,numslices):\n",
    "    print('Slice %d rmse: %.2f' % (ss+1,sig.rmse(truth[ss,:,:],sense[ss,:,:])*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining SPARK helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformattingKspaceForSpark(inputKspace,kspaceOriginal,acsregionX,acsregionY,acsx,acsy,normalizationflag):\n",
    "    [E,C,_,_] = inputKspace.shape\n",
    "    kspaceAcsCrop     = kspaceOriginal[:,:,acsregionX[0]:acsregionX[acsx-1]+1,acsregionY[0]:acsregionY[acsy-1]+1] \n",
    "    #Ground truth measured ACS data, will be used as the ground truth to compute kspace error we want learn\n",
    "    kspaceAcsGrappa   = inputKspace[:,:,acsregionX[0]:acsregionX[acsx-1]+1,acsregionY[0]:acsregionY[acsy-1]+1] \n",
    "    #GRAPPA reconstructed ACS region.  kspaceAcsCrop - kspaceAcsGrappa = d will be the supervised error we try to learn\n",
    "    kspaceAcsDifference = kspaceAcsCrop - kspaceAcsGrappa\n",
    "\n",
    "    #Splitting the difference into the real and imaginary part for the network\n",
    "    acs_difference_real = np.real(kspaceAcsDifference)\n",
    "    acs_difference_imag = np.imag(kspaceAcsDifference)\n",
    "\n",
    "    #print('acs_difference_real shape: ' + str(acs_difference_real.shape))\n",
    "    #print('acs_difference_imag shape: ' + str(acs_difference_imag.shape))\n",
    "\n",
    "    #Adding the batch dimension\n",
    "    kspace_grappa = np.copy(inputKspace)\n",
    "    kspace_grappa_real  = np.real(kspace_grappa)\n",
    "    kspace_grappa_imag  = np.imag(kspace_grappa)\n",
    "    kspace_grappa_split = np.concatenate((kspace_grappa_real, kspace_grappa_imag), axis=1)\n",
    "\n",
    "    #print('kspace_grappa_split shape: ' + str(kspace_grappa_split.shape))\n",
    "\n",
    "    #Let's do some normalization\n",
    "    chan_scale_factors_real = np.zeros((E,C),dtype = 'float')\n",
    "    chan_scale_factors_imag = np.zeros((E,C),dtype = 'float')\n",
    "\n",
    "    for e in range(E):\n",
    "        if(normalizationflag):\n",
    "            scale_factor_input = 1/np.amax(np.abs(kspace_grappa_split[e,:,:,:]))\n",
    "            kspace_grappa_split[e,:,:,:] *= scale_factor_input\n",
    "\n",
    "        for c in range(C):\n",
    "            if(normalizationflag):\n",
    "                scale_factor_real = 1/np.amax(np.abs(acs_difference_real[e,c,:,:]))\n",
    "                scale_factor_imag = 1/np.amax(np.abs(acs_difference_imag[e,c,:,:]))\n",
    "            else:\n",
    "                scale_factor_real = 1\n",
    "                scale_factor_imag = 1\n",
    "\n",
    "            chan_scale_factors_real[e,c] = scale_factor_real\n",
    "            chan_scale_factors_imag[e,c] = scale_factor_imag\n",
    "\n",
    "            acs_difference_real[e,c,:,:] *= scale_factor_real\n",
    "            acs_difference_imag[e,c,:,:] *= scale_factor_imag\n",
    "\n",
    "    acs_difference_real = np.expand_dims(acs_difference_real, axis=2)\n",
    "    acs_difference_real = np.expand_dims(acs_difference_real, axis=2)\n",
    "    acs_difference_imag = np.expand_dims(acs_difference_imag, axis=2)\n",
    "    acs_difference_imag = np.expand_dims(acs_difference_imag, axis=2)\n",
    "\n",
    "    #print('acs_difference_real shape: ' + str(acs_difference_real.shape))\n",
    "    #print('acs_difference_imag shape: ' + str(acs_difference_imag.shape))\n",
    "\n",
    "    kspace_grappa_split = torch.from_numpy(kspace_grappa_split)\n",
    "    kspace_grappa_split = kspace_grappa_split.to(device, dtype=torch.float)\n",
    "    print('kspace_grappa_split shape: ' + str(kspace_grappa_split.shape))\n",
    "\n",
    "    acs_difference_real = torch.from_numpy(acs_difference_real)\n",
    "    acs_difference_real = acs_difference_real.to(device, dtype=torch.float)\n",
    "    print('acs_difference_real shape: ' + str(acs_difference_real.shape))\n",
    "\n",
    "    acs_difference_imag = torch.from_numpy(acs_difference_imag)\n",
    "    acs_difference_imag = acs_difference_imag.to(device, dtype=torch.float)\n",
    "    print('acs_target_imag shape: ' + str(acs_difference_imag.shape))\n",
    "    \n",
    "    return kspace_grappa_split, acs_difference_real, acs_difference_imag, chan_scale_factors_real, chan_scale_factors_imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingSparkNetwork(kspaceGrappaSplit,acsDifferenceReal,acsDifferenceImag,acsx,acsy,learningRate,iterations):\n",
    "    '''\n",
    "    Trains a SPARK networks given some appropriately formatted grappa kspace, acsDifferenceReal, and acsDifferenceImaginary\n",
    "    Inputs:\n",
    "        kspaceGrappaSplit: allContrasts x 2 * allChannels x M x N,             Grappa reconstructed kspace which will \n",
    "                                                                               be used to learn error\n",
    "        acsDifferenceReal: allContrasts x allChaannels x 1 x 1 x M x N,        Difference between measured and GRAPPA\n",
    "                                                                               ACS real portion\n",
    "        acsDifferenceImag: allContrasts x allChaannels x 1 x 1 M x N,          Difference between measured and GRAPPA\n",
    "                                                                               ACS imag portion             \n",
    "        acs:               acss x 1,                                           Indices of ACS region\n",
    "        learningRate:      scalar,                                             Learaning rate for the networks\n",
    "        iterations:        scalar,                                             Number of iterations we want to train\n",
    "    Outputs:\n",
    "        A network which should reconstruct each contrast and channel        \n",
    "    '''\n",
    "    \n",
    "    [E,C,_,_,_,_] = acsDifferenceReal.shape\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    #Training the real models\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    real_models      = {}\n",
    "    real_model_names = []\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for e in range(0,E):\n",
    "        for c in range(0,C):\n",
    "            model_name = 'model' + 'E' + str(e) + 'C' + str(c) + 'r'\n",
    "            model = models.SPARK_Netv2(coils = C,kernelsize = 3,acsx = acsx, acsy = acsy)\n",
    "            \n",
    "            model.to(device)\n",
    "            \n",
    "            kspsplit = torch.unsqueeze(kspaceGrappaSplit[e,:,:,:],axis = 0)\n",
    "            \n",
    "            print('Training {}'.format(model_name))\n",
    "            \n",
    "            optimizer = optim.Adam(model.parameters(),lr=learningRate)\n",
    "            running_loss = 0\n",
    "            \n",
    "            for epoch in range(iterations):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                _,loss_out = model(kspsplit)\n",
    "                loss = criterion(loss_out,acsDifferenceReal[e,c,:,:,:,:])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss = loss.item()\n",
    "                if(epoch == 0):\n",
    "                    print('Initial Loss: %.10f' % (running_loss))\n",
    "            \n",
    "            real_model_names.append(model_name)\n",
    "            real_models.update({model_name:model})\n",
    "            print('Final Loss:   %.10f' % (running_loss))\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    #Training the imaginary model\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    imag_models      = {}\n",
    "    imag_model_names = []\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for e in range(0,E):\n",
    "        for c in range(0,C):\n",
    "            model_name = 'model' + 'E' + str(e) + 'C' + str(c) + 'i'            \n",
    "            model = models.SPARK_Netv2(coils = C,kernelsize = 3,acsx = acsx, acsy = acsy)\n",
    "            \n",
    "            model.to(device)\n",
    "            \n",
    "            kspsplit = torch.unsqueeze(kspaceGrappaSplit[e,:,:,:],axis = 0)\n",
    "            \n",
    "            print('Training {}'.format(model_name))\n",
    "            \n",
    "            optimizer    = optim.Adam(model.parameters(),lr = learningRate)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for epoch in range(iterations):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                _,loss_out = model(kspsplit)\n",
    "                loss = criterion(loss_out,acsDifferenceImag[e,c,:,:,:,:])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss = loss.item()\n",
    "                if(epoch == 0):\n",
    "                        print('Initial Loss: %.10f' % (running_loss))\n",
    "                        \n",
    "            imag_model_names.append(model_name)\n",
    "            imag_models.update({model_name : model})\n",
    "\n",
    "            print('Final Loss:   %.10f' % (running_loss))\n",
    "\n",
    "    return real_models,real_model_names,imag_models,imag_model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applySparkCorrection(kspaceToCorrect,kspaceGrappaSplit,real_model,imag_model,chanScaleFactorReal,chanScaleFactorImag):\n",
    "    '''\n",
    "    Given a set of models trained for a particular contrast, apply SPARK to all of the contrasts\n",
    "    Inputs:\n",
    "        kspaceToCorrect   - M x N,       Kspace that we want to correct\n",
    "        kspaceGrappasplit - allcoils x M x N  Kspace that will be used to reconstuct the particular for this kspace\n",
    "        real_model      - model          Model for correcting the real component\n",
    "        imag_model      - model          Model for correcting the imaginary component\n",
    "        chanScaleFactor - Scalar         Scaling parameter for the particular piece of kspace which is corrected\n",
    "    outputs:\n",
    "        kspaceCorrected - M x N       Corrected kspace\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    correctionr = real_model(torch.unsqueeze(kspaceGrappaSplit,axis=0))[0].cpu().detach().numpy()\n",
    "    correctioni = imag_model(torch.unsqueeze(kspaceGrappaSplit,axis=0))[0].cpu().detach().numpy()\n",
    "    corrected = correctionr[0,0,:,:]/chanScaleFactorReal + 1j * correctioni[0,0,:,:] / chanScaleFactorImag + kspaceToCorrect\n",
    "    \n",
    "    return corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### computing k-space for training spark network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kspaceSense      = np.transpose(col(sig.fft2c(coils*smsSense)),(1,0,2,3))\n",
    "kspaceAcsSpark   = np.transpose(col((sig.fft2c(slicesShiftedCoils))),(1,0,2,3))\n",
    "acsregionX = np.arange((Nro)//2 - acsx // 2,(Nro)//2 + acsx//2) \n",
    "acsregionY = np.arange(N//2 - acsy // 2,N//2 + acsy//2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training spark network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Reformatting the data\n",
    "[kspace_grappa_split, acs_difference_real, acs_difference_imag,chan_scale_factors_real,chan_scale_factors_imag] = \\\n",
    "    reformattingKspaceForSpark(kspaceSense,kspaceAcsSpark,acsregionX,acsregionY,acsx,acsy,normalizationflag)\n",
    "\n",
    "realSparkGrappaModels,realSparkGrappaNames,imagSparkGrappaModels,imagSparkGrappaNames = \\\n",
    "    trainingSparkNetwork(kspace_grappa_split,acs_difference_real,acs_difference_imag,acsregionX,acsregionY,learningRate,sparkIterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating k-space to which we apply correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kspaceSenseToCorrect      = np.transpose(col(sig.fft2c(coils*smsSenseAcs)),(1,0,2,3))\n",
    "\n",
    "[kspace_grappasplit, acs_difference_real, acs_difference_imag,chan_scale_factors_real,chan_scale_factors_imag] = \\\n",
    "    reformattingKspaceForSpark(kspaceSenseToCorrect,kspaceAcsSpark,acsregionX,acsregionY,acsx,acsy,normalizationflag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performing correction and acs replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will use each model contrast to reconstruct each recon contrast\n",
    "kspaceCorrected    = np.zeros((1,C,Nro,N),dtype = complex)\n",
    "\n",
    "for e in range(0,1):\n",
    "    for c in range(0,C):\n",
    "        #Perform reconstruction coil by coil\n",
    "        model_namer = 'model' + 'E' + str(e) + 'C' + str(c) + 'r'\n",
    "        model_namei = 'model' + 'E' + str(e) + 'C' + str(c) + 'i'\n",
    "\n",
    "        real_model = realSparkGrappaModels[model_namer]\n",
    "        imag_model = imagSparkGrappaModels[model_namei]\n",
    "\n",
    "        kspaceToCorrect   = kspaceSenseToCorrect[e,c,:,:]\n",
    "        kspaceGrappaSplit = kspace_grappa_split[e,:,:,:]\n",
    "\n",
    "        currentCorrected = \\\n",
    "                applySparkCorrection(kspaceToCorrect,kspaceGrappaSplit,real_model,imag_model,\\\n",
    "                    chan_scale_factors_real[e,c], chan_scale_factors_imag[e,c])\n",
    "\n",
    "        kspaceCorrected[e,c,:,:] = currentCorrected       \n",
    "            \n",
    "#ACS replaced\n",
    "kspaceCorrectedReplaced    = np.copy(kspaceCorrected)\n",
    "\n",
    "\n",
    "kspaceCorrectedReplaced[:,:,acsregionX[0]:acsregionX[acsx-1],acsregionY[0]:acsregionY[acsy-1]] = \\\n",
    "    kspaceAcsSpark[:,:,acsregionX[0]:acsregionX[acsx-1],acsregionY[0]:acsregionY[acsy-1]] \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-performing cartesian slice-group reconstruction with corrected k-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Compute the adjoint of the kspace data\n",
    "kadj = senseAdjoint(np.transpose(kspaceCorrectedReplaced,(1,0,2,3)),coils,1)\n",
    "\n",
    "if(cudaflag):\n",
    "    coils   = cp.asarray(coils)\n",
    "    kadj    = cp.asarray(kadj)\n",
    "    \n",
    "#-Defining the normal operator and performing the reconstruction\n",
    "normal = lambda x: senseAdjoint(senseForward(x.reshape(1,numslices,Nro,N),coils,1),\\\n",
    "                                          coils,1).ravel()\n",
    "\n",
    "print('SENSE reconstruction ...',end='')\n",
    "smsSenseSpark = cp.asnumpy(iterative.conjgrad(normal,kadj.ravel(),kadj.ravel(),\\\n",
    "                                         ite = 20)).reshape(1,numslices,Nro,N)\n",
    "\n",
    "print(' Done.')\n",
    "\n",
    "coils = cp.asnumpy(coils)\n",
    "kadj  = cp.asnumpy(kadj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualizing cartesian sense with spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viscrop = lambda x: x[:,768//2-128:768//2+128,:]\n",
    "    \n",
    "spark = viscrop(np.squeeze(performshift(np.expand_dims(np.reshape(smsSenseSpark,(numslices,Nro,N)),axis=0),shifts,-1),axis=0))\n",
    "\n",
    "display = sig.nor(np.concatenate((truth,sense,spark),axis = 0))\n",
    "sig.mosaic(display,3,numslices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sense Total rmse:   %.2f' % (sig.rmse(truth,sense)*100) )\n",
    "print('Spark Total rmse:   %.2f' % (sig.rmse(truth,spark)*100) )\n",
    "\n",
    "if(numslices > 1):\n",
    "    for ss in range(0,numslices):\n",
    "        print('Slice %d:' %(ss+1))\n",
    "        print('  sense rmse: %.2f' % (sig.rmse(truth[ss,:,:],sense[ss,:,:])*100))\n",
    "        print('  spark rmse: %.2f' % (sig.rmse(truth[ss,:,:],spark[ss,:,:])*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining shifted psf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Shift the psf and restructure to match readout oversampled dimensions\n",
    "psf = np.copy(psf_slices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining wave-encoded operators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sforwave(x,coils):\n",
    "    return coils * x\n",
    "\n",
    "def sadjwave(x,coils):\n",
    "    xp = cp.get_array_module(x)\n",
    "    return xp.sum(xp.conj(coils)*x,-4,keepdims = True)\n",
    "\n",
    "Fx    = lambda x: sig.fft(x,ax = -2)    #Perform fft in the readout direction\n",
    "Fy    = lambda x: sig.fft(x,ax = -1)    #Perform fft in the phaseencode direction\n",
    "Fxadj = lambda x: sig.ifft(x,ax = -2)   #Perform ifft in the readout direction\n",
    "Fyadj = lambda x: sig.ifft(x,ax = -1)   #Perform ifft in the phaseencode direction\n",
    "\n",
    "def waveForward(x,psf): #Perform the forward wave operation through psf modeling\n",
    "    return psf * x\n",
    "\n",
    "def waveAdjoint(x,psf): #Perform the adjoint wave operation through psf modeling\n",
    "    xp = cp.get_array_module(x)\n",
    "    return xp.conj(psf) * x \n",
    "\n",
    "def senseWaveForward(x,maps,psf,mask):\n",
    "    xp = cp.get_array_module(x)\n",
    "    return mask*col(Fy(waveForward(Fx(sforwave(x,maps)),psf)))\n",
    "\n",
    "def senseWaveAdjoint(x,maps,psf,mask):\n",
    "    xp = cp.get_array_module(x)\n",
    "    return sadjwave(Fxadj(waveAdjoint(Fyadj(exp(xp.conj(mask) * x)),psf)),maps)\n",
    "\n",
    "def analyzePsf(x,psf):    \n",
    "    return Fxadj(psf*Fx(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating wave-encoded k-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Generate the undersampling mask\n",
    "maskWave = np.zeros((C,1,Nro,N),dtype = complex)\n",
    "maskWave[:,:,:,::Ry] = 1\n",
    "\n",
    "maskWaveAcs = np.zeros((C,1,Nro,N),dtype = complex)\n",
    "maskWaveAcs[:,:,:,::Ry] = 1\n",
    "maskWaveAcs[:,:,:,acsregionY[0]:acsregionY[acsy-1]] = 1\n",
    "\n",
    "kspaceWave = col(maskWave * (sig.fft(psf*sig.fft(slicesShiftedCoils,-2),-1)))\n",
    "kspaceWaveAcs = col(maskWaveAcs * (sig.fft(psf*sig.fft(slicesShiftedCoils,-2),-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performing wave-encoded reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Compute the adjoint of the kspace data\n",
    "kadjWave = senseWaveAdjoint(kspaceWave,coils,psf,maskWave)\n",
    "kadjWaveAcs = senseWaveAdjoint(kspaceWaveAcs,coils,psf,maskWaveAcs)\n",
    "\n",
    "if(cudaflag):\n",
    "    coils       = cp.asarray(coils)\n",
    "    maskWave    = cp.asarray(maskWave)\n",
    "    maskWaveAcs = cp.asarray(maskWaveAcs)\n",
    "    kadjWave    = cp.asarray(kadjWave)\n",
    "    kadjWaveAcs = cp.asarray(kadjWaveAcs)\n",
    "    psf         = cp.asarray(psf)\n",
    "    \n",
    "#-Defining the normal operator and performing the reconstruction\n",
    "normalWave = lambda x: senseWaveAdjoint(senseWaveForward(x.reshape(1,numslices,Nro,N),coils,psf,maskWave),\\\n",
    "                                          coils,psf,maskWave).ravel()\n",
    "\n",
    "normalWaveAcs = lambda x: senseWaveAdjoint(senseWaveForward(x.reshape(1,numslices,Nro,N),coils,psf,maskWaveAcs),\\\n",
    "                                          coils,psf,maskWaveAcs).ravel()\n",
    "\n",
    "print('WAVE SENSE reconstruction ...',end='')\n",
    "smsWave = cp.asnumpy(iterative.conjgrad(normalWave,kadjWave.ravel(),kadjWave.ravel(),\\\n",
    "                                         ite = 20)).reshape(1,numslices,Nro,N)\n",
    "\n",
    "smsWaveAcs = cp.asnumpy(iterative.conjgrad(normalWaveAcs,kadjWaveAcs.ravel(),kadjWaveAcs.ravel(),\\\n",
    "                                         ite = 20)).reshape(1,numslices,Nro,N)\n",
    "print(' Done.')\n",
    "\n",
    "coils    = cp.asnumpy(coils)\n",
    "maskWave = cp.asnumpy(maskWave)\n",
    "kadjWave = cp.asnumpy(kadjWave)\n",
    "psf      = cp.asnumpy(psf)\n",
    "maskWaveAcs = cp.asnumpy(maskWaveAcs)\n",
    "kadjWaveAcs = cp.asnumpy(kadjWaveAcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualizing wave-encoded reconstruction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = viscrop(np.squeeze(performshift(np.expand_dims(np.reshape(smsWaveAcs,(numslices,Nro,N)),axis=0),shifts,-1)))\n",
    "\n",
    "display = sig.nor(np.concatenate((truth,sense,wave),axis = 0))\n",
    "sig.mosaic(display,3,numslices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sense Total rmse:   %.2f' % (sig.rmse(truth,sense)*100) )\n",
    "print('Wave  Total rmse:   %.2f' % (sig.rmse(truth,wave)*100) )\n",
    "\n",
    "for ss in range(0,numslices):\n",
    "    print('Slice %d:' %(ss+1))\n",
    "    print('  sense rmse: %.2f' % (sig.rmse(truth[ss,:,:],sense[ss,:,:])*100))\n",
    "    print('  wave  rmse: %.2f' % (sig.rmse(truth[ss,:,:],wave[ss,:,:])*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up k-space to train SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kspaceWaveSpark      = np.transpose(col(sig.fft(psf*sig.fft(coils*smsWave,-2),-1)),(1,0,2,3))\n",
    "kspaceWaveAcsSpark   = np.transpose(col(sig.fft(psf*sig.fft(slicesShiftedCoils,-2),-1)),(1,0,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training wave-spark network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformatting the data\n",
    "[kspace_grappa_split, acs_difference_real, acs_difference_imag,chan_scale_factors_real,chan_scale_factors_imag] = \\\n",
    "    reformattingKspaceForSpark(kspaceWaveSpark,kspaceWaveAcsSpark,acsregionX,acsregionY,acsx,acsy,normalizationflag)\n",
    "\n",
    "realSparkGrappaModels,realSparkGrappaNames,imagSparkGrappaModels,imagSparkGrappaNames = \\\n",
    "    trainingSparkNetwork(kspace_grappa_split,acs_difference_real,acs_difference_imag,acsregionX,acsregionY,learningRate,sparkIterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating k-space wiith which to apply correction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kspaceSenseToCorrect = np.copy(kspaceWaveSpark) #what I did originally\n",
    "kspaceSenseToCorrect = np.transpose(col(sig.fft(psf*sig.fft(coils*smsWaveAcs,-2),-1)),(1,0,2,3))\n",
    "\n",
    "[kspace_grappa_split, acs_difference_real, acs_difference_imag,chan_scale_factors_real,chan_scale_factors_imag] = \\\n",
    "    reformattingKspaceForSpark(kspaceSenseToCorrect,kspaceWaveAcsSpark,acsregionX,acsregionY,acsx,acsy,normalizationflag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applying spark correction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will use each model contrast to reconstruct each recon contrast\n",
    "kspaceCorrectedWave    = np.zeros((1,C,Nro,N),dtype = complex)\n",
    "\n",
    "for e in range(0,1):\n",
    "    for c in range(0,C):\n",
    "        #Perform reconstruction coil by coil\n",
    "        model_namer = 'model' + 'E' + str(e) + 'C' + str(c) + 'r'\n",
    "        model_namei = 'model' + 'E' + str(e) + 'C' + str(c) + 'i'\n",
    "\n",
    "        real_model = realSparkGrappaModels[model_namer]\n",
    "        imag_model = imagSparkGrappaModels[model_namei]\n",
    "\n",
    "        kspaceToCorrect   = kspaceSenseToCorrect[e,c,:,:]\n",
    "        kspaceGrappaSplit = kspace_grappa_split[e,:,:,:]\n",
    "\n",
    "        currentCorrected = \\\n",
    "                applySparkCorrection(kspaceToCorrect,kspaceGrappaSplit,real_model,imag_model,\\\n",
    "                    chan_scale_factors_real[e,c], chan_scale_factors_imag[e,c])\n",
    "\n",
    "        kspaceCorrectedWave[e,c,:,:] = currentCorrected       \n",
    "            \n",
    "#ACS replaced\n",
    "kspaceCorrectedReplacedWave   = np.copy(kspaceCorrectedWave)\n",
    "\n",
    "\n",
    "kspaceCorrectedReplacedWave[:,:,acsregionX[0]:acsregionX[acsx-1],acsregionY[0]:acsregionY[acsy-1]] = \\\n",
    "    kspaceWaveAcsSpark[:,:,acsregionX[0]:acsregionX[acsx-1],acsregionY[0]:acsregionY[acsy-1]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performing slice-group reconstruction after spark correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Compute the adjoint of the kspace data\n",
    "kadjWave = senseWaveAdjoint(np.transpose(kspaceCorrectedReplacedWave,(1,0,2,3)),coils,psf,1)\n",
    "\n",
    "if(cudaflag):\n",
    "    coils       = cp.asarray(coils)\n",
    "    kadjWave    = cp.asarray(kadjWave)\n",
    "    psf         = cp.asarray(psf)\n",
    "    \n",
    "#-Defining the normal operator and performing the reconstruction\n",
    "normalWave = lambda x: senseWaveAdjoint(senseWaveForward(x.reshape(1,numslices,Nro,N),coils,psf,1),\\\n",
    "                                          coils,psf,1).ravel()\n",
    "\n",
    "print('WAVE SENSE reconstruction ...',end='')\n",
    "smsWaveSpark = cp.asnumpy(iterative.conjgrad(normalWave,kadjWave.ravel(),kadjWave.ravel(),\\\n",
    "                                         ite = 20)).reshape(1,numslices,Nro,N)\n",
    "\n",
    "print(' Done.')\n",
    "\n",
    "coils    = cp.asnumpy(coils)\n",
    "kadjWave = cp.asnumpy(kadjWave)\n",
    "psf      = cp.asnumpy(psf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### displaying results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viscrop = lambda x: x[:,768//2-128:768//2+128,:]\n",
    "    \n",
    "sparkWave = viscrop(np.squeeze(performshift(np.expand_dims(np.reshape(smsWaveSpark,(numslices,Nro,N)),axis=0),shifts,-1),axis=0))\n",
    "\n",
    "display = sig.nor(np.concatenate((truth,wave,sparkWave),axis = 0))\n",
    "sig.mosaic(display,3,numslices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('wave  Total rmse:   %.2f' % (sig.rmse(truth,wave)*100) )\n",
    "print('spark Total rmse:   %.2f' % (sig.rmse(truth,sparkWave)*100) )\n",
    "\n",
    "for ss in range(0,numslices):\n",
    "    print('Slice %d:' %(ss+1))\n",
    "    print('  wave  rmse: %.2f' % (sig.rmse(truth[ss,:,:],wave[ss,:,:])*100))\n",
    "    print('  spark rmse: %.2f' % (sig.rmse(truth[ss,:,:],sparkWave[ss,:,:])*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'truth': np.squeeze(truth),\n",
    "           'sense': np.squeeze(sense),\n",
    "           'spark': np.squeeze(spark),\n",
    "           'wave':  np.squeeze(wave),\n",
    "           'sparkwave': np.squeeze(sparkWave),\n",
    "           'mbfactor': numslices,\n",
    "           'Ry': Ry,\n",
    "           'acsy': acsy,           \n",
    "           'Iterations': sparkIterations,\n",
    "           'learningRate': learningRate,\n",
    "           'slices':  slices,\n",
    "           'fovshift':fovshift}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
